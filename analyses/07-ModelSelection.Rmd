---
title: "07 Model Selection"
author: "Galina M. JÃ¶nsson"
date: "20/04/2021"
runtime: shiny
output: 
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
---

To do list:
* Run next species
* Annotate shiny plotting code
* Annotate Rhat_lists function
* Plot detection probability





# Background & standardisation

## Background

#### Here, I compare the three occupancy model formulations:   
- **Model A**: specifies that list length should be considered as a categorical variable. There are 3 classes: BNM records (excluding BMS records), UKBMS records, and NHM records.  
   
- **Model B**: specifies that list length should be considered as both a continuous variable and a categorical variable. There are 3 classes: BNM records (excluding BMS records) are considered continuous, whilst UKBMS records and NHM records are considered as categorical.  
   
- **Model C**: specifies that list length should be considered as both continuous and categorical variables with no year effect estimated for one class (NHM records). There are 3 classes: BNM records (excluding BMS records) are considered continuous, whilst UKBMS records and NHM records are considered as categorical.  



#### For each of 12 species: 
1. *Erebia epiphron*   
2. *Carterocephalus palaemon*   
3. *Melitaea athalia*   
4. *Polyommatus bellargus*   
5. *Thecla betulae*   
6. *Limenitis camilla*   
7. *Polygonia c-album*   
8. *Erebia aethiops*   
9. *Aglais urticae*   
10. *Pararge aegeria*   
11. *Lycaena phlaeas*   
12. *Pieris rapae*   




See 04-Occupancy trends for in detail methods of species selection but in short, species were selected based on their range (small, medium or large), weather they are Habitat specialists or Wider Countryside Species, mean annual detection probability variance and record numbers. Species that show much variation and uncertainty are expected to benefit most from the Model C detection sub-model formulation. Note that there are no Small Range Wider Countryside Species nor any Large Range Habitat Specialist; hence, I chose four species from each of the two groups Small Range Habitat Specialist and Large Range Wider Countryside Species.   



**Small Range Habitat Specialist** (four species)   
The three species with the largest mean annual detection probability standard deviations (*Erebia epiphron*, *Carterocephalus palaemon* and *Melitaea athalia*) and the sixth (of 13) most variable species, *Polyommatus bellargus*, which has most records of all species in this group.   
   
   
   
**Medium Range Habitat Specialist** (two species)   
The species with the largest mean annual detection probability standard deviation (*Thecla betulae*) and fourth (of 16) most variable species, *Limenitis camilla*, because among the species in this group, it is the only species with recent range expansions and has among the highest record numbers.   
   
   
   
**Medium Range Wider Countryside Species** (two species)   
The largest mean annual detection probability standard deviation (*Polygonia c-album*) and the third (of 10) most variable species, *Erebia aethiops*, as it has among the fewest records of the species in this group.   
   
   
   
**Large Range Wider Countryside Species** (four species)   
The three species with the largest mean annual detection probability standard deviations (*Aglais urticae*, *Pararge aegeria* and *Lycaena phlaeas*) and the fourth (of 13) most variable species, *Pieris rapae*, as the genus of the third (*Aglais io*) is already represented in the sample.   







```{r load-model-outputs, message=FALSE, warning=FALSE}
# Load required packages
require(dplyr)


# Create a vector with species names to name model outputs
ModelNames <- c('Aglais_urticae',
               'Carterocephalus_palaemon',
               'Erebia_aethiops',
               'Erebia_epiphron',
               'Limenitis_camilla',
               'Lycaena_phlaeas',
               'Melitaea_athalia',
               'Pararge_aegeria',
               'Pieris_rapae',
               'Polygonia_c.album',
               'Polyommatus_bellargus',
               'Thecla_betulae')




########################################################## 
#######################  Model A  ########################
##########################################################

#ModelNames_catLL <- paste(ModelNames, "catLL", sep="_") # Add '_catLL' to model names
#catLL_list <- list() # Create an empty list
#input_dir <- "../outputs/catLL-outputs/"  # Define input directory

# List files to loop through
#files <- list.files(path = paste(input_dir), 
#                    ignore.case = TRUE, 
#                    pattern = '\\.rds$')

# Loop through, read the rds files, append to list and name elements
#for(i in 1:length(files)){
  # read rds file and append to list
#  catLL_list[[i]] <- readRDS(file.path(input_dir, files[i])) 
  # name element
#  names(catLL_list)[[i]] <- paste(ModelNames_catLL[i])
#}




########################################################## 
#######################  Model B  ########################
##########################################################

# Load and list model outputs. I specify files as folder contains all species
mixLL_list <- list(
  readRDS("../outputs/mixLL-outputs/results_Aglais_urticae_crick_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Carterocephalus_palaemon_ctag_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Erebia_aethiops_crick_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Erebia_epiphron_crick_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Limenitis_camilla_ctag_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Lycaena_phlaeas_crick_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Melitaea_athalia_watson_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Pararge_aegeria_watson_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Pieris_rapae_crick_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Polygonia_c_album_watson_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Polyommatus_bellargus_crick_mixLL.rds"),
  readRDS("../outputs/mixLL-outputs/results_Thecla_betulae_crick_mixLL.rds")
)

# Add model name '_mixLL' to species names
ModelNames_mixLL <- paste(ModelNames, "mixLL", sep="_")

# Name list elements accordingly
for(i in 1:length(mixLL_list)){
  names(mixLL_list)[[i]] <- paste(ModelNames_mixLL[i])
}




########################################################## 
#######################  Model C  ########################
##########################################################

ModelNames_mixLL2 <- paste(ModelNames, "mixLL2", sep="_") # Add '_mixLL2' to model names
mixLL2_list <- list() # Create an empty list
input_dir <- "../outputs/mixLL2-outputs/" # Define input directory

# List files to loop through
files <- list.files(path = paste(input_dir), 
                    ignore.case = TRUE, 
                    pattern = '\\.rds$')

# Loop through, read the rds files, append to list and name elements
for(i in 1:length(files)){
  # read rds file and append to list
  mixLL2_list[[i]] <- readRDS(file.path(input_dir, files[i])) 
  # name element
  names(mixLL2_list)[[i]] <- paste(ModelNames_mixLL2[i])
}




########################################################## 
##############  Check model B & C outputs ################
##########################################################

# Check that the number of species observations and sites where the species have been collected and recorded are equal for model B and C. In other words whether the models are based on the same data set. 
for (i in 1:length(mixLL_list)) {
  if(isFALSE(mixLL_list[[i]]$species_observations == mixLL2_list[[i]]$species_observations)){
    print("stop, two species_observations differ")
  }
  if(isFALSE(mixLL_list[[i]]$species_sites == mixLL2_list[[i]]$species_sites)){
    print("stop, two species_sites differ")
  }
}




########################################################## 
##################  Rhat: Convergence ####################
##########################################################

# Source the function that checks convergence, i.e. is Rhat >1.1?
source("./function-summarise_Rhat_lists.R")

# Use function to summarise whether all occupancy estimates have converged
RhatSummary <- summarise_Rhat_lists(append(#catLL_list,
                                     mixLL_list,
                                     mixLL2_list), 
                              verbose=FALSE)

# Check whether species have not converged (converged-column == "N")
NotConvergedSpp <- subset(RhatSummary, grepl("N", converged))

# If any of the model outputs have occupancy estimates that have not converged (Rhat >1.1), display them as a table.
if(nrow(NotConvergedSpp) > 0){
  knitr::kable(NotConvergedSpp)
}
```


## Visualisation

### Occupancy estimates
```{r plot-occu-outputs, message=FALSE, echo=FALSE}
require(shiny)
require(ggplot2)
require(labelmachine)

### Source plotting function
source("./fig-plot.Occdet_G.R")

# Change ModelNames vetor to species names with spaces
spp_names <- gsub(ModelNames, patt = "_", repl=" ")
spp_names <- sub(spp_names, patt = "c.album", repl="c-album")

# Name the lists of outputs their species names
names(mixLL_list)[1:12] <- spp_names
names(mixLL2_list)[1:12] <- spp_names


# Create a dictionary translating Latin names to common names
dict <- new_lama_dictionary(common_names = 
                              c("Aglais urticae" = 'Small Tortoiseshell',
                                "Carterocephalus palaemon" = 'Chequered Skipper',
                                "Erebia aethiops" = 'Scotch Argus',
                                "Erebia epiphron" = 'Mountain Ringlet',
                                "Limenitis camilla" = 'White Admiral',
                                "Lycaena phlaeas" = 'Small Copper',
                                "Melitaea athalia" = 'Heath Fritillary',
                                "Pararge aegeria" = 'Speckled Wood',
                                "Pieris rapae" = 'Small White',
                                "Polygonia c-album" = 'Comma',
                                "Polyommatus bellargus" = 'Adonis Blue',
                                "Thecla betulae" = 'Brown Hairstreak'))


# Plot occupancy estimates as a shiny app (currently two models per species)

shinyApp(
  ui = fluidPage(
    selectInput("species_choice", label = "Select species",
  choices = spp_names, selected ="Aglais urticae"), 
  plotOutput("occuPlot")
  ),
  server = function(input, output) {
    output$occuPlot <- renderPlot({
      
      vec <- paste(input$species_choice)  ###
      vec_labeled <- lama_translate_(vec, dict, "common_names")  ###
      
      plot.occDet_G(mixLL_list[[input$species_choice]], mixLL2_list[[input$species_choice]]) +
        ggtitle(label = paste(input$species_choice), #)
                subtitle = paste(vec_labeled)) + ###
        theme(plot.title=element_text(face="italic")) +
        theme(text=element_text(size=18))
    })
  },
  options = list(height = 500)
)
```



### Detection probability estimates
```{r plot-det-outputs, message=FALSE, echo=FALSE, eval=FALSE}
require(shiny)
require(ggplot2)

### Source plotting function
source("./fig-plot.Occdet_G.R")



##### TEST
spp_names <- gsub(ModelNames, patt = "_", repl=" ")
spp_names <- sub(spp_names, patt = ".", repl="-")


### Vector of species names
spp_names <- c('Aglais urticae',
               'Carterocephalus palaemon',
               'Erebia aethiops',
               'Erebia epiphron',
               'Limenitis camilla',
               'Lycaena phlaeas',
               'Melitaea athalia',
               'Pararge aegeria',
               'Pieris rapae',
               'Polygonia c-album',
               'Polyommatus bellargus',
               'Thecla betulae')

names(mixLL_list)[1:12] <- spp_names
names(mixLL2_list)[1:12] <- spp_names



### Vector of common names


library(labelmachine)
dict <- new_lama_dictionary(
  common_names = c(Aglais urticae = 'Small Tortoiseshell',
                Carterocephalus palaemon = 'Chequered Skipper',
                Erebia aethiops = 'Scotch Argus',
                Erebia epiphron = 'Mountain Ringlet',
                Limenitis camilla = 'White Admiral',
                Lycaena phlaeas = 'Small Copper',
                Melitaea athalia = 'Heath Fritillary',
                Pararge aegeria = 'Speckled Wood',
                Pieris rapae = 'Small White',
                Polygonia c-album = 'Comma',
                Polyommatus bellargus = 'Adonis Blue',
                Thecla betulae = 'Brown Hairstreak')

common_names <- c('Small Tortoiseshell',
                  'Chequered Skipper',
                  'Scotch Argus',
                  'Mountain Ringlet',
                  'White Admiral',
                  'Small Copper',
                  'Heath Fritillary',
                  'Speckled Wood',
                  'Small White',
                  'Comma',
                  'Adonis Blue',
                  'Brown Hairstreak')





shinyApp(
  ui = fluidPage(
    selectInput("species_choice", label = "Select species",
  choices = spp_names, selected ="Aglais urticae"), 
  plotOutput("detPlot")
  ),
  server = function(input, output) {
    output$detPlot <- renderPlot({
      
      par(mfrow=c(1,3), oma=c(0,0,2,0))
      
      mtext(paste(input$species_choice), line=0, side=3, outer=TRUE, cex=2)
      
      plot_DetectionOverTime(mixLL_list[[input$species_choice]], 
                             min.yr = 1900, 
                             legend_labels = c("BNM_LL1/Year_Effect", 
                                               "UKBMS", 
                                               "NHCs", 
                                               "BNM_LL5"), 
                             legend_title = "Data Type") + 
        ggtitle("Model B (mixLL)")
      
      
      plot_DetectionOverTime(mixLL2_list[[input$species_choice]], 
                             min.yr = 1900, 
                             legend_labels = c("BNM_LL1/Year_Effect", 
                                               "UKBMS", 
                                               "NHCs", 
                                               "BNM_LL5"), 
                             legend_title = "Data Type") + 
        ggtitle("Model C (mixLL2)")
      
      
        ggtitle(label = paste(input$species_choice)) +
        theme(plot.title=element_text(face="italic")) +
        theme(text=element_text(size=18))
    })
  },
  #options = list(height = 800)
  #options = list(height = 600)
)



```







### DIC
```{r DIC, cache=TRUE, message=FALSE, echo=FALSE}
# Create empty data frame to populate
summary_out <- data.frame(Species = as.character(),
                          Best_fit = as.character(),
                          Model_B = as.numeric(),
                          Model_C = as.numeric(),
                          Difference = as.numeric())

# loop through BUGSoutput for each species pair in turn
for (i in 1:length(mixLL_list)) { # If Model B's DIC is lower than C's
  if(mixLL_list[[i]]$BUGSoutput$DIC < mixLL2_list[[i]]$BUGSoutput$DIC) {
    Best <- "B"    # Name 'Best' B
  } else {
      Best <- "C"    # Else name 'Best' C
  }
  summary_out[i, "Species"] <- paste(paste("*", spp_names[i], sep = ""), "*", sep = "")     # Populate species_name column from spp_names list and surround by asterisks
  summary_out[i, "Best_fit"] <-  Best     # Populate Best_fit column with lowest DIC model
  summary_out[i, "Model_B"] <-  mixLL_list[[i]]$BUGSoutput$DIC     # Enter Model B's DIC value
  summary_out[i, "Model_C"] <-  mixLL2_list[[i]]$BUGSoutput$DIC     # Enter Model C's DIC value
  summary_out[i, "Difference"] <- abs(mixLL_list[[i]]$BUGSoutput$DIC - mixLL2_list[[i]]$BUGSoutput$DIC)     # Enter the difference between Model B's and C's DIC values
  }

knitr::kable(summary_out)
```
**Reminder**: DIC differences are 'absolute', not relative to the DIC estimates themselves (e.g. a difference of 2 is the same thing when models' DICs are 80k and 79998 vs 2 and 4?)


# Posterior Predictive Checks

## Extract and summarise Py

> (1)   
For each of *v* visits in each speciesâ model, extract 99 samples from the posterior distribution of the probability that an observation was made on that visit. In practical terms, this probability is the product of the true (unknown) occupancy, *z*~*it*~, and the detection probability, *p*~*itv*~


As the model formulation is coded in the following way:   
```{r model-example, cache=TRUE, message=FALSE, eval=FALSE}
for(j in 1:nvisit) {   
y[j] ~ dbern(Py[j])   
y.new[j] ~ dbern(Py[j])   
Py[j] <- z[Site[j],Year[j]]*p[j]   
logit(p[j]) <-  alpha.p[Year[j]] + LL.p * logL[j] + dtype2.p * DATATYPE2[j] + dtype3.p * DATATYPE3[j] }   
}  
```
   
   
the following line gives the product of the true occupancy, *z*~*it*~, and the detection probability, *p*~*itv*~
```{r py-demonstration, cache=TRUE, message=FALSE, eval=FALSE}
Py[j] <- z[Site[j],Year[j]]*p[j]   
```   

In other words, we want to extract Py[j]

> (2)   
Use each of the 99 sets of probabilities to sample a vector of potential observations under the model, by treating each visit as a potential Bernoulli trial. These vectors are 99 realizations of *y*~*rep*~

> (3)   
For each realization *y*~*rep*~ and for each year, calculate the annual proportion of sites in which the species was recorded; denote this proportion, for species *s* and year *t*, by *T*~*st*~(*y*~*rep*~)


**Species left to run**
* *Pararge aegeria*
* *Pieris rapae*
* *Polygonia c-album*
* *Polyommatus bellargus*
* *Thecla betulae*

```{r PostPredChecks1, eval=FALSE, message=FALSE}
require("rjags")
require("coda")
require("reshape2")
require("dplyr")
require("sparta")
require("lattice")
require("LearnBayes")
require("R2jags")
require("sparta")


Pararge_aegeria_mixLL <- readRDS("../outputs/mixLL-outputs/results_Pararge_aegeria_watson_mixLL.rds")


###########################
############ 1 ############
###########################


# recompile the model
Pararge_aegeria_mixLL$model$recompile()

#out$model$recompile()

# Sample 100 iterations of each of the 3 chains and thin by 3, giving 99 samples
samp <- rjags:::coda.samples(model=Pararge_aegeria_mixLL$model, 
                             parallel=TRUE, n.cores=3,
                             variable.names="Py", 
                             n.iter=100, # Define number of iterations to run
                             thin=3) # Define thinning


###########################
############ 2 ############
###########################

# Create vectors that are are 99 realizations of yrep

# Use the 99 sets of probabilities & sample a vector of simulated observations under the model, by treating each visit as a potential Bernoulli trial. Here, we use rbinom as Bernoulli trial 
Y_rep <- lapply(samp, function(x) apply(x, 1:2, rbinom, n=1, size=1))


### Tidy the 99 realizations of yrep       

# What does this do? 
Y_rep <- melt(Y_rep)

# Tidy VisitID
Y_rep$VisitID <- as.character(gsub(Y_rep$Var2, pa="Py\\[", repl=""))
Y_rep$VisitID <- as.numeric(gsub(Y_rep$VisitID, pa="\\]", repl=""))

# Tidy iteration
Y_rep$iter <- with(Y_rep, Var1 + max(Var1)*(L1 - 1))

# Include year, siteID and the actual observation (y)        
# load the raw data
#temp_data <- out$model$data()
temp_data <- Pararge_aegeria_mixLL$model$data()
temp_data <- as.data.frame(with(temp_data, cbind(Site, Year, y)))
temp_data$VisitID <- 1:nrow(temp_data)
Y_rep <- merge(Y_rep[,-c(1,2,4)], temp_data)
        
#with(Y_rep, table(y,value))


###########################
############ 3 ############
###########################
        
# next calculate the reporting rate in differing ways
# first, for each site:year combination (i.e., yrep) report the number of sites for which a positive record was made
RR1 <- Y_rep %>% group_by(Site, Year, iter) %>%
  summarise(obs = max(y),sim = max(value)) %>%
  ungroup()
# the data in RR1 refer to whether the species was recorded in each site in each year
# save this file
write.csv(RR1, "../outputs/posteriorPredictiveChecks-outputs/Pararge_aegeria_mixLL_RR1.csv")

# next, the mean of these across years (i.e., Tst(yrep))
RR2 <- RR1 %>% group_by(Year, iter) %>%
          summarise(obs_meanSitesPerYear = mean(obs),
                    sim_meanSitesPerYear = mean(sim)
          ) %>%
          ungroup()

# the data in RR2 refer to the proportion of Sites with positive records per Year
# save this file
write.csv(RR2, "../outputs/posteriorPredictiveChecks-outputs/Pararge_aegeria_mixLL_RR2.csv")









######################################################################


Pararge_aegeria_mixLL2 <- readRDS("../outputs/mixLL2-outputs/results_Pararge_aegeria_crick_mixLL2.rds")


###########################
############ 1 ############
###########################


# recompile the model
Pararge_aegeria_mixLL2$model$recompile()

#out$model$recompile()

# Sample 100 iterations of each of the 3 chains and thin by 3, giving 99 samples
samp <- rjags:::coda.samples(model=Pararge_aegeria_mixLL2$model, 
                             parallel=TRUE, n.cores=3,
                             variable.names="Py", 
                             n.iter=100, # Define number of iterations to run
                             thin=3) # Define thinning


###########################
############ 2 ############
###########################

# Create vectors that are are 99 realizations of yrep

# Use the 99 sets of probabilities & sample a vector of simulated observations under the model, by treating each visit as a potential Bernoulli trial. Here, we use rbinom as Bernoulli trial 
Y_rep <- lapply(samp, function(x) apply(x, 1:2, rbinom, n=1, size=1))


### Tidy the 99 realizations of yrep       

# What does this do? 
Y_rep <- melt(Y_rep)

# Tidy VisitID
Y_rep$VisitID <- as.character(gsub(Y_rep$Var2, pa="Py\\[", repl=""))
Y_rep$VisitID <- as.numeric(gsub(Y_rep$VisitID, pa="\\]", repl=""))

# Tidy iteration
Y_rep$iter <- with(Y_rep, Var1 + max(Var1)*(L1 - 1))

# Include year, siteID and the actual observation (y)        
# load the raw data
#temp_data <- out$model$data()
temp_data <- Pararge_aegeria_mixLL2$model$data()
temp_data <- as.data.frame(with(temp_data, cbind(Site, Year, y)))
temp_data$VisitID <- 1:nrow(temp_data)
Y_rep <- merge(Y_rep[,-c(1,2,4)], temp_data)
        
#with(Y_rep, table(y,value))


###########################
############ 3 ############
###########################
        
# next calculate the reporting rate in differing ways
# first, for each site:year combination (i.e., yrep) report the number of sites for which a positive record was made
RR1 <- Y_rep %>% group_by(Site, Year, iter) %>%
  summarise(obs = max(y),sim = max(value)) %>%
  ungroup()
# the data in RR1 refer to whether the species was recorded in each site in each year
# save this file
write.csv(RR1, "../outputs/posteriorPredictiveChecks-outputs/Pararge_aegeria_mixLL2_RR1.csv")

# next, the mean of these across years (i.e.,, Tst(yrep))
RR2 <- RR1 %>% group_by(Year, iter) %>%
          summarise(obs_meanSitesPerYear = mean(obs),
                    sim_meanSitesPerYear = mean(sim)
          ) %>%
          ungroup()

# the data in RR2 refer to the proportion of Sites with positive records per Year
# save this file
write.csv(RR2, "../outputs/posteriorPredictiveChecks-outputs/Pararge_aegeria_mixLL2_RR2.csv")

```





> (4)
Calculate *T*~*gt*~(*y*~*rep*~) for each replicate dataset as the mean of *T*~*st*~(*y*~*rep*~) across species in each taxonomic group, *g*.

This is not relevant for me 


> (5)
Calculate the mean *m* across years as *T*~*gm*~(*y*~*rep*~) for each replicate dataset


```{r readData}
require("reshape2")
require("dplyr")
require("tidyr")
require("ggplot2")
q <- c(0.025, 0.975)

#system.time({

path_in <- "../outputs/posteriorPredictiveChecks-outputs/"
spp_files <- paste(path_in, list.files(path=path_in, 
                                       pattern="\\RR2.csv$",
                                       recursive = TRUE), sep="/")
data <- lapply(spp_files, read.csv)

# how many taxa?
print(length(data))


#append the species names
sppnames <- gsub(spp_files, patt = paste0(path_in, "/"), repl="")
sppnames <- gsub(sppnames, patt = "_RR2.csv", repl="")
sppnames <- sub(sppnames, patt = "_", repl=".")
names(data) <- sppnames


# coerce to a single dataframe
#data2 <- do.call(rbind, data) # loses info about species ID
sppMeanSites <- melt(data, id=1:5)

# separate Model and Species
sppMeanSites <- sppMeanSites %>% 
  separate(L1, into=c("Species", "Model"), 
           sep="_", remove=TRUE)
#})


# Assign correct years
sppMeanSites$Year <- sppMeanSites$Year + 1899
```


Now we're ready to calculate three other summary statistics:
sppVarSites: the variance across years in the proportion of sites with a record
modelMeanSites: the annual mean (across species) in the proportion of sites with a record per model
modelVarSites: the variance across years in the above



> (6)
Calculate Tgvar(*y*~*rep*~) as the variance across years in Tgt(*y*~*rep*~) for each replicate dataset.

> (7)
Calculate the observed mean proportion of sites with records, Tgm(y), and the variance across years, Tgvar(y), for each replicate dataset.


```{r variance & taxon}
library("dplyr")
#system.time({
# now the variance across years 
# sppVarSites <- sppMeanSites %>% group_by(Taxon, Species, iter) %>%
sppVarSites <- sppMeanSites %>% group_by(Model, Species, iter) %>%
  summarise(obs_varSitesPerYear = var(obs_meanSitesPerYear),
            sim_varSitesPerYear = var(sim_meanSitesPerYear)
  ) %>%
  ungroup()

# now summarise these stats to Taxon level
# We'll calculate the mean proportion of sites with records for species in each taxon
modelMeanSites <- sppMeanSites %>% group_by(Model, Year, iter) %>%
  summarise(obs_meanSitesPerYear = mean(obs_meanSitesPerYear),
            sim_meanSitesPerYear = mean(sim_meanSitesPerYear)
  ) %>%
  ungroup()

# finally, the variance among years
modelVarSites <- modelMeanSites %>% group_by(Model, iter) %>%
  summarise(obs_varSitesPerYear = var(obs_meanSitesPerYear),
            sim_varSitesPerYear = var(sim_meanSitesPerYear)
  ) %>%
  ungroup
#})
```


> (8)
Summarize the distributions of Tgm(y) and Tgvar(y) as the mean and 95% credible intervals to demonstrate the variation in summary measures that can reasonably be expected under the model.
Summarise the data, including the Bayesian p value

```{r Bayesian P}
sppMeanSites_Summ <- sppMeanSites %>% 
  group_by(Model, Species) %>%
    summarise(Bp = mean(obs_meanSitesPerYear > sim_meanSitesPerYear),
              obs = mean(obs_meanSitesPerYear),
              sim_mean = mean(sim_meanSitesPerYear),
              sim_lower = quantile(sim_meanSitesPerYear, q[1]),
              sim_upper = quantile(sim_meanSitesPerYear, q[2]),
              ) %>%
    ungroup()

sppVarSites_Summ <- sppVarSites %>% 
  group_by(Model, Species) %>%
  summarise(Bp = mean(obs_varSitesPerYear > sim_varSitesPerYear),
            obs = mean(obs_varSitesPerYear),
            sim_mean = mean(sim_varSitesPerYear),
            sim_lower = quantile(sim_varSitesPerYear, q[1]),
            sim_upper = quantile(sim_varSitesPerYear, q[2]),
  ) %>%
  ungroup()


modelMeanSites_Summ <- modelMeanSites %>% 
  group_by(Model) %>%
  summarise(Bp = mean(obs_meanSitesPerYear > sim_meanSitesPerYear),
            obs = mean(obs_meanSitesPerYear),
            sim_mean = mean(sim_meanSitesPerYear),
            sim_lower = quantile(sim_meanSitesPerYear, q[1]),
            sim_upper = quantile(sim_meanSitesPerYear, q[2]),
  ) %>%
  ungroup()

modelVarSites_Summ <- modelVarSites %>% 
  group_by(Model) %>%
  summarise(Bp = mean(obs_varSitesPerYear > sim_varSitesPerYear),
            obs = mean(obs_varSitesPerYear),
            sim_mean = mean(sim_varSitesPerYear),
            sim_lower = quantile(sim_varSitesPerYear, q[1]),
            sim_upper = quantile(sim_varSitesPerYear, q[2]),
  ) %>%
  ungroup()
```

Now plot the results

```{r plot, echo=FALSE}
plot_PredPostTest <- function(data, title=NULL){
  gp <- ggplot(data = data) +
    geom_point(aes(x=obs, y=sim_mean, col=Model)) +
    geom_errorbar(aes(x=obs, ymin=sim_lower, ymax=sim_upper, col=Model)) +
    geom_abline(aes(intercept=0, slope=1)) + 
    scale_x_log10() + scale_y_log10() + 
    xlab("observed from data") + ylab("model prediction") + 
    ggtitle(title) + theme_bw()
  print(gp)
}
  
#do.call(plot_PredPostTest, list(sppMeanSites_Summ,
#                                sppVarSites_Summ,
#                                taxonMeanSites_Summ,
#                                taxonVarSites_Summ))

#lapply(list(sppMeanSites_Summ, 
#            sppVarSites_Summ, 
#            taxonMeanSites_Summ,
#            taxonVarSites_Summ), 
#       plot_PredPostTest)

mapply(data = list(sppMeanSites_Summ, 
                  sppVarSites_Summ, 
                  modelMeanSites_Summ,
                  modelVarSites_Summ), 
        title = list("Mean (across years) proportion of sites with a record", 
                  "Variance (across years) in proportion of sites per year", 
                  "Mean proportion of sites per year (mean across species)",
                  "Variance across years in proportion of sites per year across species"),       
       FUN = plot_PredPostTest)
```

Now plot the Bayesian p-value (the proporiton of simulated values that are lower than the observed)

```{r plot Bp, echo=FALSE}
hist(sppMeanSites_Summ$Bp)
hist(sppVarSites_Summ$Bp)
hist(modelMeanSites_Summ$Bp) ### MixLL_2 on the left
hist(modelVarSites_Summ$Bp)
```

Finally save the outputs
```{r save, echo=FALSE}
#write.csv(taxonMeanSites_Summ, file="taxonMeanSites_Summ.csv")
#write.csv(taxonVarSites_Summ, file="taxonVarSites_Summ.csv")
```


